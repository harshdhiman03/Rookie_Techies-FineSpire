{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Tc6ya1494BI"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "genai.configure(api_key=\"AIzaSyCcNx2Yy5igMvpD99iiEItNqYDUuweIvTQ\")\n",
        "\n",
        "\n",
        "generation_config = {\n",
        "    \"temperature\": 0.8,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 64,\n",
        "    \"max_output_tokens\": 8192,\n",
        "    \"response_mime_type\": \"text/plain\",\n",
        "}\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-flash\",\n",
        "    generation_config=generation_config,\n",
        ")\n",
        "\n",
        "@app.route(\"/\")\n",
        "def print():\n",
        "    return \"Hello\"\n",
        "\n",
        "@app.route('/generate', methods=['POST'])\n",
        "def generate():\n",
        "    data = request.get_json()\n",
        "\n",
        "    prompts = data.get(\"prompts\", [])\n",
        "    if not prompts:\n",
        "        return jsonify({\"error\": \"No prompts provided\"}), 400\n",
        "\n",
        "    response = model.generate_content(prompts)\n",
        "    return jsonify({\"response\": response.text})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=5000)\n"
      ]
    }
  ]
}